{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# ROOT = Path(\"\") ## For local use\n",
        "ROOT = Path(\"content/pitch_tracker\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVe5a1v7W2E4",
        "outputId": "67f7f1d3-8f4f-4731-cb28-2863fae1295e"
      },
      "outputs": [],
      "source": [
        "!apt install fluidsynth\n",
        "\n",
        "!git clone https://github.com/Serge-Andre-MASSON/pitch_tracker.git\n",
        "%pip install /content/pitch_tracker"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VVKH2Bd-4JiQ"
      },
      "source": [
        "As a first step, one needs to load a configuration file. Here the default conf.yaml is loaded.\n",
        "\n",
        "Then an example wave file is loaded and its waveform is extracted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "5g8eUScfXeIf",
        "outputId": "ae1549a3-8d98-453f-93f3-e66c92e6c4b5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "\n",
        "from pitch_tracker.config import Config\n",
        "from pitch_tracker.audio_file import AudioFile\n",
        "\n",
        "\n",
        "config = Config(ROOT / \"conf.yaml\")\n",
        "\n",
        "audio_file_path = ROOT / \"wavs/ce_soir_a_la_brume.wav\"\n",
        "display(Audio(audio_file_path))\n",
        "\n",
        "audio_file = AudioFile(\n",
        "    audio_file_path,\n",
        "    **config.get_audio_file_config()\n",
        ")\n",
        "\n",
        "waveform = audio_file.get_waveform()\n",
        "plt.plot(waveform)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z-KLgJYR4rBg"
      },
      "source": [
        "Below, waveform's features (amplitude and frequency) are extracted. With those it's possible to extract beats from a kmeans based peaks detection algorithm. It appears that extracted beats differs and this is the reason why they are extracted from both of those features : sometimes, frequency moves whereas amplitude does not (eg : a bend or a pull off)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "xty6QUFUHSXE",
        "outputId": "d7be0c15-11bd-42f3-ec5e-3f7aeb67b86f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pitch_tracker.waveform_features import Amplitude, Frequency\n",
        "from pitch_tracker.beat import AmplitudeBeat, FrequencyBeat\n",
        "\n",
        "\n",
        "amplitude = Amplitude(waveform, **config.get_amplitude_config())\n",
        "amplitude_features = amplitude.get_features()\n",
        "\n",
        "amplitude_beat = AmplitudeBeat(amplitude)\n",
        "amplitude_beats = amplitude_beat.get_beats()\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(amplitude_features)\n",
        "plt.scatter(\n",
        "    amplitude_beats,\n",
        "    np.zeros_like(amplitude_beats),\n",
        "    marker=\"*\",\n",
        "    c=\"r\"\n",
        ")\n",
        "\n",
        "frequency = Frequency(waveform, **config.get_frequency_config())\n",
        "frequency_features = frequency.get_features()\n",
        "\n",
        "frequency_beat = FrequencyBeat(frequency)\n",
        "frequency_beats = frequency_beat.get_beats()\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(frequency_features)\n",
        "plt.scatter(\n",
        "    frequency_beats,\n",
        "    np.zeros_like(frequency_beats),\n",
        "    marker=\"*\",\n",
        "    c=\"r\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rbcpry056ErD"
      },
      "source": [
        "Those beats can be merged according to a proximity threshold using the Beat object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "wPFDzVrWKaQq",
        "outputId": "1289e63e-bfd7-4c77-fb73-65c8a77e3973"
      },
      "outputs": [],
      "source": [
        "from pitch_tracker.beat import Beat\n",
        "\n",
        "\n",
        "beat = Beat(amplitude, frequency, **config.get_beat_config())\n",
        "waveform_beats = beat.get_beats()\n",
        "\n",
        "plt.plot(waveform)\n",
        "plt.scatter(\n",
        "    waveform_beats,\n",
        "    np.zeros_like(\n",
        "        waveform_beats)-.5,\n",
        "    marker=\"*\",\n",
        "    c=\"r\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zFaAwol4LBRr"
      },
      "source": [
        "From here, things needs to be improve. The main idea is to get the most likely pitches between each beats and infer the bpm from beats distribution. \n",
        "The algorithm to find the bpm is yet to be improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpNAkl89Kyxr"
      },
      "outputs": [],
      "source": [
        "from pitch_tracker.bpm import get_bpm_and_midi_ticks\n",
        "\n",
        "\n",
        "beats_in_ms = waveform_beats / audio_file.sampling_rate * 1000\n",
        "bpm, ticks = get_bpm_and_midi_ticks(beats_in_ms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jubYY_zEK-84"
      },
      "outputs": [],
      "source": [
        "frequency_beats = waveform_beats / waveform.size * frequency.features_length\n",
        "frequency_beats = frequency_beats.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3EM6dzYLV2P"
      },
      "outputs": [],
      "source": [
        "from pitch_tracker.pitch_finder import read_notes\n",
        "\n",
        "\n",
        "_, all_freq, available_pitches = read_notes()\n",
        "\n",
        "pitches_index = [\n",
        "    np.argmin(\n",
        "        np.abs(all_freq - f)\n",
        "    ) for f in frequency.features]\n",
        "\n",
        "all_pitches = [int(available_pitches[index])\n",
        "               if index else 0 for index in pitches_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OUswjadQNRh"
      },
      "outputs": [],
      "source": [
        "last_beat = frequency_beats[0]\n",
        "pitches = []\n",
        "for beat in frequency_beats[1:]:\n",
        "    pitches_ = all_pitches[last_beat: beat]\n",
        "    pitch = max(pitches_, key=lambda i: pitches_.count(i))\n",
        "    if pitch:\n",
        "        pitches.append(pitch)\n",
        "    last_beat = beat"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve2-cYss7fRN"
      },
      "source": [
        "With bpm, ticks (duration between beats) and pitches it is easy to create a midi file that play back the raw original .wav file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tnyt5ERlQUCw"
      },
      "outputs": [],
      "source": [
        "from pitch_tracker.midi import Midi\n",
        "\n",
        "\n",
        "midi_conf = config.get_midi_config()\n",
        "\n",
        "midi = Midi(bpm, guitar=24, **midi_conf)\n",
        "\n",
        "\n",
        "for pitch, midi_tick in zip(pitches, ticks):\n",
        "    midi.add_note(midi_tick, pitch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "RJkDldhuQXIe",
        "outputId": "5012f9e0-ebe8-42ea-f352-4478a74b5934"
      },
      "outputs": [],
      "source": [
        "wav_path = ROOT / (\"tmp.wav\")\n",
        "midi.save_wav_to(wav_path)\n",
        "display(Audio(wav_path))\n",
        "wav_path.unlink()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNq6P/i8JAfZZBBi6MFjEsl",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
